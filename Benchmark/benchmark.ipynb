{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43773169-db42-46cc-a90d-12e89902ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203bfcbd-d1ff-4de2-8cd4-6bfd39e287a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "%autoreload 2\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974d13dc-dafe-43ad-97d5-3e463b7a73ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f546f76a-8f4c-4002-8346-31bec5d5cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try/except/finally\n",
    "# if `track_backward` (+)\n",
    "# make one function (module, inputs=(shape or tensor), device, repeats, warmup) -> dict (+)\n",
    "# torch.cuda.empty_cache() in the very beginning (+)\n",
    "# please type list instead of array (+)\n",
    "# module `repr` into the dataframe/dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32dfd927-590d-4f63-8a94-b629837a87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_memory(reset_memory=True):\n",
    "        \n",
    "    mb = 2 ** 20\n",
    "    if reset_memory:\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "    max_memory = torch.cuda.max_memory_allocated(device) / mb\n",
    "        \n",
    "    return max_memory\n",
    "    \n",
    "    \n",
    "def tracker(module, shape, device, repeats, warmup, track_backward=True) -> dict:\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "    # calculate time and memory of the inputs \n",
    "    start_memory = calc_memory()\n",
    "        \n",
    "    start.record()\n",
    "    inputs = torch.randn(shape)\n",
    "    inputs = inputs.to(device)\n",
    "    end.record()\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "        \n",
    "    inputs_memory = calc_memory(reset_memory=False) - start_memory\n",
    "    \n",
    "    # calculate time and memory for to(device) operation\n",
    "    current_memory = calc_memory()\n",
    "        \n",
    "    start.record()\n",
    "    module.to(device)\n",
    "    end.record()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    loading_time = start.elapsed_time(end)\n",
    "        \n",
    "    new_current_memory = calc_memory()\n",
    "    module_memory_consumption = new_current_memory - current_memory\n",
    "    \n",
    "    # calculate macs and parameters number\n",
    "    macs, params = get_model_complexity_info(module, tuple(inputs.shape[1:]), print_per_layer_stat=False)\n",
    "       \n",
    "    inputs.requires_grad = True\n",
    "    \n",
    "    \n",
    "    for i in range(warmup):\n",
    "        outputs = module(inputs)\n",
    "        del outputs\n",
    "    \n",
    "    # calculate time and memory for forward operation\n",
    "    forward_start_memory = calc_memory()\n",
    "    temp_outputs = module(inputs)\n",
    "    forward_end_memory = calc_memory(reset_memory=False) - forward_start_memory\n",
    "    \n",
    "    # calculate time and memory for backward operation \n",
    "    if track_backward:\n",
    "        backward_start_memory = calc_memory()\n",
    "        temp_outputs.backward(torch.ones_like(temp_outputs))\n",
    "        backward_end_memory = calc_memory(reset_memory=False) - backward_start_memory\n",
    "        backward_timings = []\n",
    "        \n",
    "    del temp_outputs\n",
    "    \n",
    "    forward_timings = []\n",
    "    \n",
    "    for i in range(warmup, repeats):\n",
    "                \n",
    "        start.record()\n",
    "        outputs = module(inputs)\n",
    "        end.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        forward_timings.append(start.elapsed_time(end)) \n",
    "        \n",
    "        if track_backward:\n",
    "            start.record()\n",
    "            outputs.backward(torch.ones_like(outputs))\n",
    "            end.record()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            backward_timings.append(start.elapsed_time(end))\n",
    "\n",
    "        del outputs\n",
    "        \n",
    "    result = {'forward time (s)': mean(forward_timings), 'forward memory (MB)': forward_end_memory,\n",
    "              'module size (to_cuda) (MB)': module_memory_consumption, 'loading time (s)': loading_time,\n",
    "              'macs': macs, 'parameters': params}\n",
    "    \n",
    "    if track_backward:\n",
    "        result['backward time (s)'] = mean(backward_timings)\n",
    "        result['backward memory (MB)'] = backward_end_memory\n",
    "        \n",
    "    del module\n",
    "    del inputs\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb5f6be5-d8a6-4ba7-afb1-97e97399e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1, 64, 224, 224)\n",
    "\n",
    "module_collection = {'conv_64_512_1x1': nn.Conv2d(kernel_size=1, in_channels=64, out_channels=512), \n",
    "                     'conv_64_512_3x3': nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512), \n",
    "                     'bottleneck_64_512_3x3': nn.Sequential(*[nn.Conv2d(kernel_size=1, in_channels=64, out_channels=16), \n",
    "                                              nn.Conv2d(kernel_size=3, in_channels=16, out_channels=512),\n",
    "                                              ]),\n",
    "                      'conv_64_512_3x3_g2': nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=2),\n",
    "                      'conv_64_512_3x3_g8': nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=8),\n",
    "                      'conv_padding': nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512, padding=1),\n",
    "                      'conv_nn_Padding': nn.Sequential(nn.ZeroPad2d(1),\n",
    "                                                       nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512))\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91812498-ec3c-48f5-86d8-fcb705879999",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_collection_stats = pd.DataFrame(index=module_collection.keys(), \n",
    "                                               columns=['forward time (s)', 'backward time (s)',\n",
    "                                                        'forward memory (MB)','backward memory (MB)',\n",
    "                                                        'module size (to_cuda) (MB)', 'loading time (s)',\n",
    "                                                        'macs', 'parameters'])\n",
    "        \n",
    "for module_name, module_value in module_collection.items():\n",
    "    module_collection_stats.loc[module_name] = tracker(module_value, shape=shape, device=device, repeats=100,\n",
    "                                                       warmup=10, track_backward=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7072da79-de42-44ee-983e-30d0c6ee1925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward time (s)</th>\n",
       "      <th>backward time (s)</th>\n",
       "      <th>forward memory (MB)</th>\n",
       "      <th>backward memory (MB)</th>\n",
       "      <th>module size (to_cuda) (MB)</th>\n",
       "      <th>loading time (s)</th>\n",
       "      <th>macs</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conv_64_512_1x1</th>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.67 GMac</td>\n",
       "      <td>33.28 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3</th>\n",
       "      <td>2.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>14.56 GMac</td>\n",
       "      <td>295.42 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottleneck_64_512_3x3</th>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.71 GMac</td>\n",
       "      <td>75.28 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3_g2</th>\n",
       "      <td>6.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>38.18 GMac</td>\n",
       "      <td>803.33 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3_g8</th>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9.56 GMac</td>\n",
       "      <td>201.22 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_padding</th>\n",
       "      <td>2.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>14.82 GMac</td>\n",
       "      <td>295.42 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_nn_Padding</th>\n",
       "      <td>2.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>14.82 GMac</td>\n",
       "      <td>295.42 k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      forward time (s) backward time (s) forward memory (MB)  \\\n",
       "conv_64_512_1x1                   0.87               NaN               98.41   \n",
       "conv_64_512_3x3                   2.38               NaN               99.39   \n",
       "bottleneck_64_512_3x3             1.11               NaN               99.89   \n",
       "conv_64_512_3x3_g2                6.32               NaN               97.01   \n",
       "conv_64_512_3x3_g8                 1.9               NaN               95.77   \n",
       "conv_padding                      2.14               NaN              101.13   \n",
       "conv_nn_Padding                   2.17               NaN               113.6   \n",
       "\n",
       "                      backward memory (MB) module size (to_cuda) (MB)  \\\n",
       "conv_64_512_1x1                        NaN                        0.0   \n",
       "conv_64_512_3x3                        NaN                        0.0   \n",
       "bottleneck_64_512_3x3                  NaN                        0.0   \n",
       "conv_64_512_3x3_g2                     NaN                        0.0   \n",
       "conv_64_512_3x3_g8                     NaN                        0.0   \n",
       "conv_padding                           NaN                        0.0   \n",
       "conv_nn_Padding                        NaN                        0.0   \n",
       "\n",
       "                      loading time (s)        macs parameters  \n",
       "conv_64_512_1x1                   0.21   1.67 GMac    33.28 k  \n",
       "conv_64_512_3x3                   0.12  14.56 GMac   295.42 k  \n",
       "bottleneck_64_512_3x3             0.14   3.71 GMac    75.28 k  \n",
       "conv_64_512_3x3_g2                0.11  38.18 GMac   803.33 k  \n",
       "conv_64_512_3x3_g8                0.12   9.56 GMac   201.22 k  \n",
       "conv_padding                      0.16  14.82 GMac   295.42 k  \n",
       "conv_nn_Padding                   0.11  14.82 GMac   295.42 k  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_collection_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea6c82-a10f-4a48-973a-c04b0da6a11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
