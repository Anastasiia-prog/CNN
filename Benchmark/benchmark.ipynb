{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43773169-db42-46cc-a90d-12e89902ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203bfcbd-d1ff-4de2-8cd4-6bfd39e287a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "from ptflops import get_model_complexity_info\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "%autoreload 2\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974d13dc-dafe-43ad-97d5-3e463b7a73ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f546f76a-8f4c-4002-8346-31bec5d5cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try/except/finally\n",
    "# if `track_backward` (+)\n",
    "# make one function (module, inputs=(shape or tensor), device, repeats, warmup) -> dict (+)\n",
    "# torch.cuda.empty_cache() in the very beginning (+)\n",
    "# please type list instead of array (+)\n",
    "# module `repr` into the dataframe/dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32dfd927-590d-4f63-8a94-b629837a87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_memory(reset_memory=True):\n",
    "        \n",
    "    mb = 2 ** 20\n",
    "    if reset_memory:\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "    max_memory = torch.cuda.max_memory_allocated(device) / mb\n",
    "        \n",
    "    return max_memory\n",
    "    \n",
    "def tracker(module, shape, device, repeats, warmup, track_backward=True) -> dict:\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "    ###\n",
    "    # calculate time and memory of the inputs \n",
    "    start_memory = calc_memory()\n",
    "        \n",
    "    start.record()\n",
    "    inputs = torch.randn(shape)\n",
    "    inputs = inputs.to(device)\n",
    "    end.record()\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "        \n",
    "    inputs_memory = calc_memory(reset_memory=False) - start_memory\n",
    "    ###\n",
    "    \n",
    "    ###\n",
    "    # calculate time and memory for to(device) operation\n",
    "    current_memory = calc_memory()\n",
    "        \n",
    "    start.record()\n",
    "    module.to(device)\n",
    "    end.record()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    loading_time = start.elapsed_time(end)\n",
    "        \n",
    "    new_current_memory = calc_memory()\n",
    "    module_memory_consumption = new_current_memory - current_memory\n",
    "    ###\n",
    "    \n",
    "    ###\n",
    "    # calculate macs and parameters number\n",
    "    macs, params = get_model_complexity_info(module, tuple(inputs.shape[1:]), print_per_layer_stat=False)\n",
    "    ###\n",
    "       \n",
    "    inputs.requires_grad = True\n",
    "        \n",
    "    for i in range(warmup):\n",
    "        outputs = module(inputs)\n",
    "        del outputs\n",
    "    ###\n",
    "    # calculate time and memory for forward operation\n",
    "    forward_start_memory = calc_memory()\n",
    "    temp_outputs = module(inputs)\n",
    "    forward_end_memory = calc_memory(reset_memory=False) - forward_start_memory\n",
    "    \n",
    "    # calculate time and memory for backward operation \n",
    "    if track_backward:\n",
    "        backward_start_memory = calc_memory()\n",
    "        temp_outputs.backward(torch.ones_like(temp_outputs))\n",
    "        backward_end_memory = calc_memory(reset_memory=False) - backward_start_memory\n",
    "        \n",
    "    del temp_outputs\n",
    "    ###\n",
    "    forward_timings = []\n",
    "    backward_timings = []\n",
    "    \n",
    "    for i in range(warmup, repeats):\n",
    "                \n",
    "        start.record()\n",
    "        outputs = module(inputs)\n",
    "        end.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        forward_timings.append(start.elapsed_time(end)) \n",
    "\n",
    "        start.record()\n",
    "        outputs.backward(torch.ones_like(outputs))\n",
    "        end.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        backward_timings.append(start.elapsed_time(end))\n",
    "\n",
    "        del outputs\n",
    "        \n",
    "    result = {'forward time (s)': mean(forward_timings), 'backward time (s)': mean(backward_timings),\n",
    "              'forward memory (MB)': forward_end_memory, 'backward memory (MB)': backward_end_memory,\n",
    "              'module size (to_cuda) (MB)': module_memory_consumption, 'loading time (s)': loading_time,\n",
    "              'macs': macs, 'parameters': params}\n",
    "        \n",
    "    del module\n",
    "    del inputs\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5f6be5-d8a6-4ba7-afb1-97e97399e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1, 64, 224, 224)\n",
    "\n",
    "module_collection = {'conv_64_512_1x1': nn.Conv2d(kernel_size=1, in_channels=64, out_channels=512), \n",
    "                     'conv_64_512_3x3': nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512), \n",
    "                     'bottleneck_64_512_3x3': nn.Sequential(*[nn.Conv2d(kernel_size=1, in_channels=64, out_channels=16), \n",
    "                                              nn.Conv2d(kernel_size=3, in_channels=16, out_channels=512),\n",
    "                                              ]),\n",
    "                      'conv_64_512_3x3_g2': nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=2),\n",
    "                      'conv_64_512_3x3_g8': nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=8),\n",
    "                      'conv_padding': nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512, padding=1),\n",
    "                      'conv_nn_Padding': nn.Sequential(nn.ZeroPad2d(1),\n",
    "                                                       nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512))\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91812498-ec3c-48f5-86d8-fcb705879999",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_collection_stats = pd.DataFrame(index=module_collection.keys(), \n",
    "                                               columns=['forward time (s)', 'backward time (s)',\n",
    "                                                        'forward memory (MB)','backward memory (MB)',\n",
    "                                                        'module size (to_cuda) (MB)', 'loading time (s)',\n",
    "                                                        'macs', 'parameters'])\n",
    "        \n",
    "for module_name, module_value in module_collection.items():\n",
    "    module_collection_stats.loc[module_name] = tracker(module_value, shape=shape, device=device, repeats=100, warmup=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7072da79-de42-44ee-983e-30d0c6ee1925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward time (s)</th>\n",
       "      <th>backward time (s)</th>\n",
       "      <th>forward memory (MB)</th>\n",
       "      <th>backward memory (MB)</th>\n",
       "      <th>module size (to_cuda) (MB)</th>\n",
       "      <th>loading time (s)</th>\n",
       "      <th>macs</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conv_64_512_1x1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.7</td>\n",
       "      <td>98.41</td>\n",
       "      <td>122.92</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.67 GMac</td>\n",
       "      <td>33.28 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3</th>\n",
       "      <td>2.26</td>\n",
       "      <td>5.99</td>\n",
       "      <td>99.39</td>\n",
       "      <td>122.17</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.56 GMac</td>\n",
       "      <td>295.42 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottleneck_64_512_3x3</th>\n",
       "      <td>1.14</td>\n",
       "      <td>4.31</td>\n",
       "      <td>99.89</td>\n",
       "      <td>121.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.71 GMac</td>\n",
       "      <td>75.28 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3_g2</th>\n",
       "      <td>5.78</td>\n",
       "      <td>16.98</td>\n",
       "      <td>96.8</td>\n",
       "      <td>108.13</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.13</td>\n",
       "      <td>38.18 GMac</td>\n",
       "      <td>803.33 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3_g8</th>\n",
       "      <td>1.83</td>\n",
       "      <td>15.53</td>\n",
       "      <td>96.14</td>\n",
       "      <td>105.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.56 GMac</td>\n",
       "      <td>201.22 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_padding</th>\n",
       "      <td>2.08</td>\n",
       "      <td>4.7</td>\n",
       "      <td>101.13</td>\n",
       "      <td>363.94</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.82 GMac</td>\n",
       "      <td>295.42 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_nn_Padding</th>\n",
       "      <td>2.14</td>\n",
       "      <td>6.14</td>\n",
       "      <td>113.6</td>\n",
       "      <td>124.36</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.82 GMac</td>\n",
       "      <td>295.42 k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      forward time (s) backward time (s) forward memory (MB)  \\\n",
       "conv_64_512_1x1                   0.89               1.7               98.41   \n",
       "conv_64_512_3x3                   2.26              5.99               99.39   \n",
       "bottleneck_64_512_3x3             1.14              4.31               99.89   \n",
       "conv_64_512_3x3_g2                5.78             16.98                96.8   \n",
       "conv_64_512_3x3_g8                1.83             15.53               96.14   \n",
       "conv_padding                      2.08               4.7              101.13   \n",
       "conv_nn_Padding                   2.14              6.14               113.6   \n",
       "\n",
       "                      backward memory (MB) module size (to_cuda) (MB)  \\\n",
       "conv_64_512_1x1                     122.92                       0.13   \n",
       "conv_64_512_3x3                     122.17                       1.75   \n",
       "bottleneck_64_512_3x3               121.33                       0.29   \n",
       "conv_64_512_3x3_g2                  108.13                       3.06   \n",
       "conv_64_512_3x3_g8                  105.84                       0.77   \n",
       "conv_padding                        363.94                       1.13   \n",
       "conv_nn_Padding                     124.36                       1.13   \n",
       "\n",
       "                      loading time (s)        macs parameters  \n",
       "conv_64_512_1x1                   0.58   1.67 GMac    33.28 k  \n",
       "conv_64_512_3x3                   0.52  14.56 GMac   295.42 k  \n",
       "bottleneck_64_512_3x3             0.33   3.71 GMac    75.28 k  \n",
       "conv_64_512_3x3_g2                1.13  38.18 GMac   803.33 k  \n",
       "conv_64_512_3x3_g8                0.42   9.56 GMac   201.22 k  \n",
       "conv_padding                      0.52  14.82 GMac   295.42 k  \n",
       "conv_nn_Padding                   0.52  14.82 GMac   295.42 k  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_collection_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea6c82-a10f-4a48-973a-c04b0da6a11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
