{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43773169-db42-46cc-a90d-12e89902ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%env CUDA_VISIBLE_DEVICES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203bfcbd-d1ff-4de2-8cd4-6bfd39e287a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "from ptflops import get_model_complexity_info\n",
    "import torchvision.models as models\n",
    "\n",
    "# from models import Resnet, ResnetD, ResNext\n",
    "\n",
    "%autoreload 2\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974d13dc-dafe-43ad-97d5-3e463b7a73ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7072da79-de42-44ee-983e-30d0c6ee1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, device, repeats=100, warmup=0, verbose=True):\n",
    "        self.device = device \n",
    "        self.repeats = repeats\n",
    "        self.warmup = warmup  \n",
    "        self.verbose = verbose\n",
    "        self.start = torch.cuda.Event(enable_timing=True)\n",
    "        self.end = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "    \n",
    "    def track(self, module, inputs): # add no_grad ?\n",
    "        \n",
    "        current_memory = self.calc_memory()\n",
    "        \n",
    "        self.start.record()\n",
    "        module.to(self.device)\n",
    "        self.end.record()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        loading_time = self.start.elapsed_time(self.end)\n",
    "        \n",
    "        new_current_memory = self.calc_memory()\n",
    "        module_memory_consumption = new_current_memory - current_memory\n",
    "        \n",
    "        macs, params = get_model_complexity_info(module, tuple(inputs.shape[1:]), print_per_layer_stat=False)\n",
    "        \n",
    "        timings = np.zeros((3, self.repeats))\n",
    "        \n",
    "        inputs.requires_grad = True\n",
    "        \n",
    "        for i in range(self.warmup):\n",
    "            outputs = module(inputs)\n",
    "            \n",
    "        forward_start_memory = self.calc_memory()\n",
    "        temp_outputs = module(inputs)\n",
    "        forward_end_memory = self.calc_memory(reset_memory=False) - forward_start_memory\n",
    "        \n",
    "        backward_start_memory = self.calc_memory()\n",
    "        temp_outputs.backward(torch.ones_like(temp_outputs))\n",
    "        backward_end_memory = self.calc_memory(reset_memory=False) - backward_start_memory\n",
    "        \n",
    "        del temp_outputs\n",
    "        \n",
    "        for i in range(self.warmup, self.repeats):\n",
    "                \n",
    "                self.start.record()\n",
    "                outputs = module(inputs)\n",
    "                self.end.record()\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                \n",
    "                timings[0][i] = self.start.elapsed_time(self.end)\n",
    "                \n",
    "                self.start.record()\n",
    "                outputs.backward(torch.ones_like(outputs))\n",
    "                self.end.record()\n",
    "                           \n",
    "                torch.cuda.synchronize()\n",
    "                           \n",
    "                timings[1][i] = self.start.elapsed_time(self.end)\n",
    "\n",
    "                del outputs\n",
    "        \n",
    "        \n",
    "        result = {'forward time (s)':timings[0].mean(), 'backward time (s)':timings[1].mean(),\n",
    "                  'forward memory (MB)':forward_end_memory, 'backward memory (MB)': backward_end_memory,\n",
    "                  'module size (to_cuda) (MB)': module_memory_consumption, 'loading time (s)': loading_time,\n",
    "                  'macs': macs, 'parameters': params}\n",
    "        \n",
    "        del module\n",
    "        del inputs\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def calc_memory(self, reset_memory=True):\n",
    "        \n",
    "        mb = 2 ** 20\n",
    "        if reset_memory:\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "        max_memory = torch.cuda.max_memory_allocated(device) / mb\n",
    "        \n",
    "        return max_memory\n",
    "    \n",
    "    def track_module_collection(self, module_collection, shape):\n",
    "        \n",
    "        start_memory = self.calc_memory()\n",
    "        \n",
    "        self.start.record()\n",
    "        inputs = torch.randn(shape)\n",
    "        inputs = inputs.to(self.device)\n",
    "        self.end.record()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        inputs_memory = self.calc_memory(reset_memory=False) - start_memory\n",
    "        \n",
    "        module_collection_stats = np.zeros((len(module_collection), 2))\n",
    "        module_collection_stats = pd.DataFrame(index=module_collection.keys(), \n",
    "                                               columns=['forward time (s)', 'backward time (s)',\n",
    "                                                        'forward memory (MB)','backward memory (MB)',\n",
    "                                                        'module size (to_cuda) (MB)', 'loading time (s)',\n",
    "                                                        'macs', 'parameters'])\n",
    "        \n",
    "        for i, module_name in enumerate(module_collection):\n",
    "            module_collection_stats.loc[module_name] = self.track(module=module_collection[module_name], inputs=inputs)\n",
    "            \n",
    "        return module_collection_stats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38df6e39-5410-474d-9e31-775791bb940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(device)\n",
    "shape = (1, 64, 224, 224)\n",
    "inputs = torch.randn(shape)\n",
    "\n",
    "module_collection = {'conv_64_512_1x1': nn.Conv2d(kernel_size=1, in_channels=64, out_channels=512), \n",
    "                     'conv_64_512_3x3': nn.Conv2d(kernel_size=3, in_channels=64, out_channels=512), \n",
    "                     'bottleneck_64_512_3x3': nn.Sequential(*[nn.Conv2d(kernel_size=1, in_channels=64, out_channels=16), \n",
    "                                              nn.Conv2d(kernel_size=3, in_channels=16, out_channels=512),\n",
    "                                              ]),\n",
    "                      'conv_64_512_3x3_g2': nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=2),\n",
    "                      'conv_64_512_3x3_g8': nn.Conv2d(kernel_size=7, in_channels=64, out_channels=512, groups=8),\n",
    "                    }\n",
    "\n",
    "module_collection_stats = tracker.track_module_collection(module_collection=module_collection, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847cb98f-78ec-46f5-b8dc-107848c8b06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward time (s)</th>\n",
       "      <th>backward time (s)</th>\n",
       "      <th>forward memory (MB)</th>\n",
       "      <th>backward memory (MB)</th>\n",
       "      <th>module size (to_cuda) (MB)</th>\n",
       "      <th>loading time (s)</th>\n",
       "      <th>macs</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conv_64_512_1x1</th>\n",
       "      <td>0.92</td>\n",
       "      <td>1.7</td>\n",
       "      <td>98.41</td>\n",
       "      <td>122.92</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.67 GMac</td>\n",
       "      <td>33.28 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3</th>\n",
       "      <td>2.32</td>\n",
       "      <td>6.15</td>\n",
       "      <td>99.39</td>\n",
       "      <td>122.51</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.64</td>\n",
       "      <td>14.56 GMac</td>\n",
       "      <td>295.42 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottleneck_64_512_3x3</th>\n",
       "      <td>1.19</td>\n",
       "      <td>4.47</td>\n",
       "      <td>99.89</td>\n",
       "      <td>121.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.71 GMac</td>\n",
       "      <td>75.28 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3_g2</th>\n",
       "      <td>5.8</td>\n",
       "      <td>17.32</td>\n",
       "      <td>96.43</td>\n",
       "      <td>108.51</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.44</td>\n",
       "      <td>38.18 GMac</td>\n",
       "      <td>803.33 k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv_64_512_3x3_g8</th>\n",
       "      <td>1.81</td>\n",
       "      <td>15.78</td>\n",
       "      <td>95.77</td>\n",
       "      <td>105.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.39</td>\n",
       "      <td>9.56 GMac</td>\n",
       "      <td>201.22 k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      forward time (s) backward time (s) forward memory (MB)  \\\n",
       "conv_64_512_1x1                   0.92               1.7               98.41   \n",
       "conv_64_512_3x3                   2.32              6.15               99.39   \n",
       "bottleneck_64_512_3x3             1.19              4.47               99.89   \n",
       "conv_64_512_3x3_g2                 5.8             17.32               96.43   \n",
       "conv_64_512_3x3_g8                1.81             15.78               95.77   \n",
       "\n",
       "                      backward memory (MB) module size (to_cuda) (MB)  \\\n",
       "conv_64_512_1x1                     122.92                       0.13   \n",
       "conv_64_512_3x3                     122.51                       1.75   \n",
       "bottleneck_64_512_3x3               121.33                       0.29   \n",
       "conv_64_512_3x3_g2                  108.51                       3.06   \n",
       "conv_64_512_3x3_g8                  105.84                       0.77   \n",
       "\n",
       "                      loading time (s)        macs parameters  \n",
       "conv_64_512_1x1                   0.59   1.67 GMac    33.28 k  \n",
       "conv_64_512_3x3                   0.64  14.56 GMac   295.42 k  \n",
       "bottleneck_64_512_3x3             0.34   3.71 GMac    75.28 k  \n",
       "conv_64_512_3x3_g2                1.44  38.18 GMac   803.33 k  \n",
       "conv_64_512_3x3_g8                0.39   9.56 GMac   201.22 k  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_collection_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea6c82-a10f-4a48-973a-c04b0da6a11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
